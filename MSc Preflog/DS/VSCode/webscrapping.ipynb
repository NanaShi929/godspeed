{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3135cd3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3223553644.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install requests\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n",
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024ac627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': None, 'reviews': None, 'level': None, 'duration': None}\n",
      "{'title': None, 'provider': None, 'rating': 'Rating,', 'reviews': '173K', 'level': 'Beginner Â· Professional Certificate Â· 3 - 6 Months', 'duration': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'title': None, 'provider': None, 'rating': 'Rating,', 'reviews': '56K', 'level': 'Beginner Â· Professional Certificate Â· 3 - 6 Months', 'duration': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # stop if the request failed\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "for card in soup.select('li')[:10]:  # Adjust the selector if necessary\n",
    "    # Title\n",
    "    title_tag = card.select_one('h2') or card.select_one('a[href*=\"/learn/\"]')\n",
    "    title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('G')  # Might need to adjust to proper tag\n",
    "    provider = provider_tag.get_text(strip=True) if provider_tag else None\n",
    "\n",
    "    # Rating\n",
    "    rating_tag = card.find(string=lambda text: text and \"Rating\" in text)\n",
    "    rating = rating_tag.split(' ')[0] if rating_tag else None\n",
    "\n",
    "    # Reviews\n",
    "    reviews_tag = card.find(string=lambda text: text and \"reviews\" in text)\n",
    "    reviews = reviews_tag.split(' ')[0] if reviews_tag else None\n",
    "\n",
    "    # Level & Duration\n",
    "    meta_text = card.get_text(separator='|')\n",
    "    # naive parsing\n",
    "    level = None\n",
    "    duration = None\n",
    "    parts = [part.strip() for part in meta_text.split('|')]\n",
    "    for part in parts:\n",
    "        if 'Beginner' in part or 'Advanced' in part:\n",
    "            level = part\n",
    "        if 'Months' in part or 'Week' in part:\n",
    "            duration = part\n",
    "\n",
    "    print({\n",
    "        'title': title,\n",
    "        'provider': provider,\n",
    "        'rating': rating,\n",
    "        'reviews': reviews,\n",
    "        'level': level,\n",
    "        'duration': duration,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9432350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Course Name': 'Google Data Analytics', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '173K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google Cybersecurity', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '56K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google Project Management:', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '133K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google Digital Marketing & E-commerce', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '43K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google IT Support', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '206K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google UX Design', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '93K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'IBM Generative AI Engineering', 'Provider': 'IBM', 'Rating': '4.6', 'Total Reviews': '91K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'IBM Data Analyst', 'Provider': 'IBM', 'Rating': '4.6', 'Total Reviews': '94K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google Advanced Data Analytics', 'Provider': 'Google', 'Rating': '4.7', 'Total Reviews': '8K reviews', 'Metadata': 'Advanced Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'IBM Data Science', 'Provider': 'IBM', 'Rating': '4.6', 'Total Reviews': '146K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'IBM AI Developer', 'Provider': 'IBM', 'Rating': '4.6', 'Total Reviews': '73K reviews', 'Metadata': 'Beginner Â· Professional Certificate Â· 3 - 6 Months'}\n",
      "{'Course Name': 'Google IT Automation with Python', 'Provider': 'Google', 'Rating': '4.7', 'Total Reviews': '50K reviews', 'Metadata': 'Advanced Â· Professional Certificate Â· 3 - 6 Months'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Each course card is an <li> tag (based on your example)\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "for card in course_cards:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        # Alternative: find p containing strong tag with text \"Skills you'll gain\"\n",
    "        p_tags = card.select('p')\n",
    "        skills_tag = None\n",
    "        for p in p_tags:\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = None\n",
    "    if skills_tag:\n",
    "        # remove the label \"Skills you'll gain: \"\n",
    "        skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    # Looks like a div with class \"css-vac8rf\" containing text like \"173K reviews\"\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    total_reviews = None\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # For (level, certificate type, duration)\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "    if course_name:  # print only if course found (avoid empty results)\n",
    "        print({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "            \n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Metadata': metadata\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4259523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Course Name': 'Google Data Analytics', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '173K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google Cybersecurity', 'Provider': 'Google', 'Rating': '4.8', 'Total Reviews': '56K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "\n",
    "for card in course_cards[:10]:\n",
    "    # extract data...\n",
    "\n",
    "# for card in course_cards:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = None\n",
    "    # First try direct string match\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        p_tags = card.select('p')\n",
    "        for p in p_tags:\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = None\n",
    "    if skills_tag:\n",
    "        skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    total_reviews = None\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # Metadata: level and duration\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "    level = None\n",
    "    duration = None\n",
    "    if metadata:\n",
    "        parts = [part.strip() for part in metadata.split('·')]\n",
    "        if len(parts) >= 1:\n",
    "            level = parts[0]\n",
    "        if len(parts) >= 3:\n",
    "            duration = parts[2]\n",
    "\n",
    "    if course_name:\n",
    "        print({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "           \n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Level': level,\n",
    "            'Duration': duration\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1b7784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Course Name': 'Google Data Analytics', 'Provider': 'Google', 'Skills': 'Data Storytelling, Rmarkdown, Data Literacy, Data Visualization, Data Presentation, Data Ethics, Data Cleansing, Interactive Data Visualization, Data Validation, Ggplot2, Tableau Software, Sampling (Statistics), Presentations, Spreadsheet Software, Data Analysis, Data Visualization Software, Stakeholder Communications, Data Processing, Interviewing Skills, Applicant Tracking Systems', 'Rating': '4.8', 'Total Reviews': '173K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google Cybersecurity', 'Provider': 'Google', 'Skills': 'Threat Modeling, Network Security, Incident Response, Vulnerability Management, Computer Security Incident Management, Hardening, Intrusion Detection and Prevention, Cyber Threat Intelligence, Threat Management, Cyber Attacks, Cybersecurity, Network Protocols, Cloud Security, Vulnerability Assessments, Bash (Scripting Language), Debugging, Linux, Interviewing Skills, Python Programming, SQL', 'Rating': '4.8', 'Total Reviews': '56K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google Project Management:', 'Provider': 'Google', 'Skills': 'Quality Management, Project Management Life Cycle, Requirements Analysis, Project Scoping, Project Closure, Project Management, Project Planning, Agile Project Management, Continuous Improvement Process, Project Controls, Backlogs, Stakeholder Communications, Milestones (Project Management), Quality Assessment, Team Management, Agile Methodology, Project Documentation, Change Management, Interviewing Skills, Applicant Tracking Systems', 'Rating': '4.8', 'Total Reviews': '133K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google Digital Marketing & E-commerce', 'Provider': 'Google', 'Skills': 'Data Storytelling, Search Engine Marketing, Media Planning, Social Media Marketing, Google Ads, Email Marketing, Social Media Strategy, Search Engine Optimization, Order Fulfillment, Social Media Management, Performance Measurement, Spreadsheet Software, A/B Testing, Customer Relationship Management, E-Commerce, Campaign Management, Loyalty Programs, Marketing, Interviewing Skills, Applicant Tracking Systems', 'Rating': '4.8', 'Total Reviews': '43K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google IT Support', 'Provider': 'Google', 'Skills': 'Computer Networking, Package and Software Management, Network Troubleshooting, Systems Administration, Cloud Infrastructure, IT Infrastructure, Information Systems Security, TCP/IP, Network Security, File Systems, Microsoft Windows, Computer Security, Network Architecture, Application Security, Desktop Support, Computer Hardware, Technical Support, Interviewing Skills, Applicant Tracking Systems, Professional Development', 'Rating': '4.8', 'Total Reviews': '206K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google UX Design', 'Provider': 'Google', 'Skills': 'Responsive Web Design, Storyboarding, Wireframing, User Experience Design, UI/UX Research, Usability Testing, Information Architecture, Presentations, User Research, Figma (Design Software), Design Reviews, Persona (User Experience), Web Content Accessibility Guidelines, Mobile Development, User Story, Cross Platform Development, Data Ethics, Usability, Interviewing Skills, Applicant Tracking Systems', 'Rating': '4.8', 'Total Reviews': '93K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'IBM Generative AI Engineering', 'Provider': 'IBM', 'Skills': 'Exploratory Data Analysis, Prompt Engineering, Data Wrangling, Large Language Modeling, Unsupervised Learning, PyTorch (Machine Learning Library), Generative AI, Restful API, ChatGPT, Keras (Neural Network Library), Data Transformation, Supervised Learning, Flask (Web Framework), Data Analysis, Data Cleansing, Data Manipulation, Deep Learning, Jupyter, Regression Analysis, Data Import/Export', 'Rating': '4.6', 'Total Reviews': '91K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'IBM Data Analyst', 'Provider': 'IBM', 'Skills': 'Exploratory Data Analysis, Data Storytelling, Data Wrangling, Dashboard, Data Visualization Software, Plotly, Data Visualization, SQL, Generative AI, Interactive Data Visualization, Data Transformation, Data Analysis, Data Cleansing, Jupyter, Big Data, IBM Cognos Analytics, Excel Formulas, Python Programming, Professional Networking, Microsoft Excel', 'Rating': '4.6', 'Total Reviews': '94K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google Advanced Data Analytics', 'Provider': 'Google', 'Skills': 'Data Storytelling, Data Visualization, Data Ethics, Exploratory Data Analysis, Sampling (Statistics), Data Presentation, Data Visualization Software, Feature Engineering, Regression Analysis, Descriptive Statistics, Statistical Hypothesis Testing, Advanced Analytics, Data Analysis, Tableau Software, Data Science, Statistical Analysis, Machine Learning, Object Oriented Programming (OOP), Interviewing Skills, Python Programming', 'Rating': '4.7', 'Total Reviews': '8K reviews', 'Level': 'Advanced Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'IBM Data Science', 'Provider': 'IBM', 'Skills': 'Exploratory Data Analysis, Data Wrangling, Dashboard, Data Visualization Software, Data Visualization, SQL, Unsupervised Learning, Plotly, Interactive Data Visualization, Data Transformation, Supervised Learning, Jupyter, Data Analysis, Data Cleansing, Data Manipulation, Data Literacy, Data Mining, Matplotlib, Generative AI, Professional Networking', 'Rating': '4.6', 'Total Reviews': '146K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'IBM AI Developer', 'Provider': 'IBM', 'Skills': 'Prompt Engineering, Software Development Life Cycle, Large Language Modeling, Software Architecture, Responsive Web Design, Restful API, ChatGPT, Flask (Web Framework), Generative AI, Software Design, Cascading Style Sheets (CSS), Jupyter, Scrum (Software Development), Application Deployment, Software Engineering, Software Design Patterns, Python Programming, Engineering Software, Machine Learning, Data Science', 'Rating': '4.6', 'Total Reviews': '73K reviews', 'Level': 'Beginner Â', 'Duration': '3 - 6 Months'}\n",
      "{'Course Name': 'Google IT Automation with Python', 'Provider': 'Google', 'Skills': 'Git (Version Control System), GitHub, Version Control, Cloud Services, Debugging, Puppet (Configuration Management Tool), Infrastructure as Code (IaC), Bash (Scripting Language), CI/CD, Cloud Computing, Technical Communication, Unit Testing, Web Services, Configuration Management, Scripting, Automation, Python Programming, Interviewing Skills, Applicant Tracking Systems, Programming Principles', 'Rating': '4.7', 'Total Reviews': '50K reviews', 'Level': 'Advanced Â', 'Duration': '3 - 6 Months'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "num_courses = 100  # Change this to scrape more or fewer courses\n",
    "\n",
    "for card in course_cards[:num_courses]:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = None\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        p_tags = card.select('p')\n",
    "        for p in p_tags:\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = None\n",
    "    if skills_tag:\n",
    "        skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    total_reviews = None\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # Metadata: level and duration\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "    level = None\n",
    "    duration = None\n",
    "    if metadata:\n",
    "        parts = [part.strip() for part in metadata.split('·')]\n",
    "        if len(parts) >= 1:\n",
    "            level = parts[0]\n",
    "        if len(parts) >= 3:\n",
    "            duration = parts[2]\n",
    "\n",
    "    if course_name:\n",
    "        print({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "            'Skills': skills,\n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Level': level,\n",
    "            'Duration': duration\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5cc362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 course cards.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "course_cards = soup.select('li.cds-ProductCard')\n",
    "print(f\"Found {len(course_cards)} course cards.\")\n",
    "\n",
    "for card in course_cards[:10]:\n",
    "    title_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    title = title_tag.text.strip() if title_tag else 'No title'\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a175c53",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:976\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     72\u001b[39m             time.sleep(\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# polite delay to avoid overloading server\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     50\u001b[39m     partner_map = get_partners()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     certificates = \u001b[43mget_certificates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mcoursera_certificates.csv\u001b[39m\u001b[33m'\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, newline=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     54\u001b[39m         writer = csv.writer(file)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mget_certificates\u001b[39m\u001b[34m(limit)\u001b[39m\n\u001b[32m     22\u001b[39m response = requests.get(url, params=params)\n\u001b[32m     23\u001b[39m response.raise_for_status()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get(\u001b[33m'\u001b[39m\u001b[33melements\u001b[39m\u001b[33m'\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:980\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def get_partners():\n",
    "    url = \"https://www.coursera.org/api/partners.v1\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    partner_map = {p['id']: p['name'] for p in data.get('elements', [])}\n",
    "    return partner_map\n",
    "\n",
    "def get_certificates(limit=10):\n",
    "    url = \"https://www.coursera.org/api/professional-certificates.v1\"\n",
    "    params = {\n",
    "        'q': 'search',\n",
    "        'query': 'professional certificates',\n",
    "        'limit': limit,\n",
    "        'fields': 'name,slug,partnerIds,description'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get('elements', [])\n",
    "\n",
    "def scrape_skills_from_page(slug):\n",
    "    \"\"\"Scrape skills from the certificate’s Coursera page.\"\"\"\n",
    "    base_url = f\"https://www.coursera.org/professional-certificates/{slug}\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Look for the skills section\n",
    "    # Inspect page to find where skills are listed; e.g., <p> with \"Skills you'll gain\"\n",
    "    skills_tag = None\n",
    "    for p in soup.find_all('p'):\n",
    "        if p.strong and \"Skills you'll gain\" in p.strong.text:\n",
    "            skills_tag = p\n",
    "            break\n",
    "    \n",
    "    if skills_tag:\n",
    "        # Remove the \"Skills you'll gain:\" label and clean text\n",
    "        skills_text = skills_tag.get_text(separator=', ', strip=True)\n",
    "        skills_text = skills_text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "        return skills_text\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    partner_map = get_partners()\n",
    "    certificates = get_certificates(limit=10)\n",
    "    \n",
    "    with open('coursera_certificates.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Name', 'Slug', 'Providers', 'Description', 'Skills'])\n",
    "        \n",
    "        for cert in certificates:\n",
    "            name = cert.get('name')\n",
    "            slug = cert.get('slug')\n",
    "            partners = [partner_map.get(pid, \"Unknown\") for pid in cert.get('partnerIds', [])]\n",
    "            description_html = cert.get('description', '')\n",
    "            description_text = BeautifulSoup(description_html, 'html.parser').get_text(separator=' ', strip=True)\n",
    "            \n",
    "            skills = scrape_skills_from_page(slug)\n",
    "            if skills is None:\n",
    "                skills = \"Not found\"\n",
    "            \n",
    "            print(f\"Saving: {name} | Skills: {skills[:50]}...\")\n",
    "            \n",
    "            writer.writerow([name, slug, \", \".join(partners), description_text, skills])\n",
    "            \n",
    "            time.sleep(2)  # polite delay to avoid overloading server\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n",
      "<html>\n",
      "\t<head>\n",
      "\t\t<title>Coursera - API Route Does Not Exist</title>\n",
      "\t</head>\n",
      "\t<body style=\"background-color:#e4e4e4\">\n",
      "\t\t<div style=\"position:absolute; top:0; bottom:0; left:0; right:0; margin:auto; height:200px; width: 600px\">\n",
      "\t\t\t<div style=\"text-align:center\">\n",
      "\t\t\t\t<img src=\"https://s3.amazonaws.com/coursera/error_pages/coursera-logo.svg\" width=\"400\">\n",
      "\t\t\t</div>\n",
      "\t\t\t<h1 style=\"text-align:center; font-family:Helvetica, Arial, sans-serif; font-weight:100; color: #555\">\n",
      "\t\t\t\tAPI Route Does Not Exist\n",
      "\t\n",
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:976\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m response = requests.get(api_url, params=params)\n\u001b[32m     39\u001b[39m response.raise_for_status()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Get partner info (to map partner IDs to partner names)\u001b[39;00m\n\u001b[32m     43\u001b[39m partners_url = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.coursera.org/api/partners.v1\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:980\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Coursera API URL for Professional Certificates search\n",
    "api_url = \"https://www.coursera.org/api/professional-certificates.v1\"\n",
    "\n",
    "params = {\n",
    "    'q': 'search',\n",
    "    'query': 'professional certificates',\n",
    "    'limit': 10,\n",
    "    'fields': 'name,partnerIds,description,slug'\n",
    "}\n",
    "\n",
    "response = requests.get(api_url, params=params)\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "# Get partner info (to map partner IDs to partner names)\n",
    "partners_url = \"https://www.coursera.org/api/partners.v1\"\n",
    "partners_response = requests.get(partners_url)\n",
    "partners_response.raise_for_status()\n",
    "partners_data = partners_response.json()\n",
    "partner_map = {p['id']: p['name'] for p in partners_data.get('elements', [])}\n",
    "\n",
    "for course in data.get('elements', []):\n",
    "    course_name = course.get('name')\n",
    "    partner_ids = course.get('partnerIds', [])\n",
    "    providers = [partner_map.get(pid, \"Unknown\") for pid in partner_ids]\n",
    "    \n",
    "    description_html = course.get('description', '')\n",
    "    # Parse description HTML with BeautifulSoup if needed (for example, to clean text)\n",
    "    soup = BeautifulSoup(description_html, 'html.parser')\n",
    "    description_text = soup.get_text(separator=' ', strip=True)\n",
    "    \n",
    "    # Since the API doesn't give rating, total reviews, skills, or metadata, set to None or fetch from page if needed\n",
    "    rating = None\n",
    "    total_reviews = None\n",
    "    skills = None\n",
    "    level = None\n",
    "    duration = None\n",
    "    \n",
    "    print({\n",
    "        'Course Name': course_name,\n",
    "        'Provider': \", \".join(providers),\n",
    "        'Description': description_text,\n",
    "        'Skills': skills,\n",
    "        'Rating': rating,\n",
    "        'Total Reviews': total_reviews,\n",
    "        'Level': level,\n",
    "        'Duration': duration\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1b20ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to coursera_courses.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = (\n",
    "    \"https://www.coursera.org/search\"\n",
    "    \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "courses_data = []\n",
    "\n",
    "for card in course_cards:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = None\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        p_tags = card.select('p')\n",
    "        for p in p_tags:\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = None\n",
    "    if skills_tag:\n",
    "        skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    total_reviews = None\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # Metadata: level and duration\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "    level = None\n",
    "    duration = None\n",
    "    if metadata:\n",
    "        parts = [part.strip() for part in metadata.split('·')]\n",
    "        if len(parts) >= 1:\n",
    "            level = parts[0]\n",
    "        if len(parts) >= 3:\n",
    "            duration = parts[2]\n",
    "\n",
    "    if course_name:\n",
    "        courses_data.append({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "            'Skills': skills,\n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Level': level,\n",
    "            'Duration': duration\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'coursera_courses.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Course Name', 'Provider', 'Skills', 'Rating', 'Total Reviews', 'Level', 'Duration'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(courses_data)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a39711b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Wait for course cards to be present\u001b[39;00m\n\u001b[32m     31\u001b[39m wait = WebDriverWait(driver, \u001b[32m15\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mli.cds-CommonCard\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m course_cards = driver.find_elements(By.CSS_SELECTOR, \u001b[33m'\u001b[39m\u001b[33mli.cds-CommonCard\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(course_cards)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m course cards\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/selenium/webdriver/support/wait.py:138\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    137\u001b[39m     time.sleep(\u001b[38;5;28mself\u001b[39m._poll)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mTimeoutException\u001b[39m: Message: \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Setup Chrome options\n",
    "options = Options()\n",
    "# options.add_argument(\"--headless\")  # Uncomment to run headless\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://www.coursera.org/search?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    "driver.get(url)\n",
    "\n",
    "# Scroll down multiple times to load more results\n",
    "SCROLL_PAUSE_TIME = 3\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "for _ in range(10):  # Scroll 10 times, adjust if needed\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# Wait for course cards to be present\n",
    "wait = WebDriverWait(driver, 15)\n",
    "wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'li.cds-CommonCard')))\n",
    "\n",
    "course_cards = driver.find_elements(By.CSS_SELECTOR, 'li.cds-CommonCard')\n",
    "print(f\"Found {len(course_cards)} course cards\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for card in course_cards[:20]:  # Limit to first 20 courses, change as needed\n",
    "    try:\n",
    "        course_name = card.find_element(By.CSS_SELECTOR, 'a.cds-CommonCard-titleLink h3').text.strip()\n",
    "    except:\n",
    "        course_name = None\n",
    "\n",
    "    try:\n",
    "        provider = card.find_element(By.CSS_SELECTOR, 'p.cds-ProductCard-partnerNames').text.strip()\n",
    "    except:\n",
    "        provider = None\n",
    "\n",
    "    try:\n",
    "        rating = card.find_element(By.CSS_SELECTOR, 'div[aria-label^=\"Rating\"] span').text.strip()\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    try:\n",
    "        total_reviews = None\n",
    "        divs = card.find_elements(By.CSS_SELECTOR, 'div.css-vac8rf')\n",
    "        for div in divs:\n",
    "            text = div.text.strip()\n",
    "            if \"reviews\" in text:\n",
    "                total_reviews = text\n",
    "                break\n",
    "    except:\n",
    "        total_reviews = None\n",
    "\n",
    "    try:\n",
    "        metadata_text = card.find_element(By.CSS_SELECTOR, 'div.cds-CommonCard-metadata p.css-vac8rf').text.strip()\n",
    "        parts = [part.strip() for part in metadata_text.split('·')]\n",
    "        level = parts[0] if len(parts) > 0 else None\n",
    "        duration = parts[2] if len(parts) > 2 else None\n",
    "    except:\n",
    "        level = None\n",
    "        duration = None\n",
    "\n",
    "    data.append({\n",
    "        'Course Name': course_name,\n",
    "        'Provider': provider,\n",
    "        'Rating': rating,\n",
    "        'Total Reviews': total_reviews,\n",
    "        'Level': level,\n",
    "        'Duration': duration\n",
    "    })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save data to CSV\n",
    "keys = data[0].keys() if data else []\n",
    "with open('coursera_professional_certificates.csv', 'w', newline='', encoding='utf-8') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(data)\n",
    "\n",
    "print(\"Data saved to coursera_professional_certificates.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b3dbdcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:976\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m headers = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m response = requests.get(url, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m results = data[\u001b[33m\"\u001b[39m\u001b[33mlinked\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcourses\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     15\u001b[39m courses = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:980\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    976\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    978\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    979\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "url = \"https://www.coursera.org/api/catalogResults.v2?q=search&query=professional%20certificate&limit=50&includes=partnerIds,courseId&fields=courseId,domainTypes,partners.v1(name),description\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()\n",
    "\n",
    "results = data[\"linked\"][\"courses\"]\n",
    "\n",
    "courses = []\n",
    "\n",
    "for course in results:\n",
    "    courses.append({\n",
    "        \"Course Name\": course.get(\"name\"),\n",
    "        \"Description\": course.get(\"description\"),\n",
    "        \"Course ID\": course.get(\"id\")\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "with open(\"coursera_api_courses.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=courses[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(courses)\n",
    "\n",
    "print(\"Saved to coursera_api_courses.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b808e0b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '/home/student/Downloads/Courses.html': No scheme supplied. Perhaps you meant https:///home/student/Downloads/Courses.html?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingSchema\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# url = (\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     \"https://www.coursera.org/search\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     10\u001b[39m url=(\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/home/student/Downloads/Courses.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m response.raise_for_status()\n\u001b[32m     16\u001b[39m soup = BeautifulSoup(response.text, \u001b[33m'\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/sessions.py:575\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[32m    563\u001b[39m req = Request(\n\u001b[32m    564\u001b[39m     method=method.upper(),\n\u001b[32m    565\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     hooks=hooks,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m prep = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m proxies = proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    579\u001b[39m settings = \u001b[38;5;28mself\u001b[39m.merge_environment_settings(\n\u001b[32m    580\u001b[39m     prep.url, proxies, stream, verify, cert\n\u001b[32m    581\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/sessions.py:484\u001b[39m, in \u001b[36mSession.prepare_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    481\u001b[39m     auth = get_netrc_auth(request.url)\n\u001b[32m    483\u001b[39m p = PreparedRequest()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:367\u001b[39m, in \u001b[36mPreparedRequest.prepare\u001b[39m\u001b[34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_method(method)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_headers(headers)\n\u001b[32m    369\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_cookies(cookies)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/msc-74/vs/venv/lib/python3.12/site-packages/requests/models.py:438\u001b[39m, in \u001b[36mPreparedRequest.prepare_url\u001b[39m\u001b[34m(self, url, params)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(*e.args)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No scheme supplied. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No host supplied\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMissingSchema\u001b[39m: Invalid URL '/home/student/Downloads/Courses.html': No scheme supplied. Perhaps you meant https:///home/student/Downloads/Courses.html?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# url = (\n",
    "#     \"https://www.coursera.org/search\"\n",
    "#     \"?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH\"\n",
    "# )\n",
    "\n",
    "url=(\n",
    "    \"/home/student/Downloads/Courses.html\"\n",
    ")\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "courses_data = []\n",
    "\n",
    "for card in course_cards:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = None\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        p_tags = card.select('p')\n",
    "        for p in p_tags:\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = None\n",
    "    if skills_tag:\n",
    "        skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    total_reviews = None\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # Metadata: level and duration\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "    level = None\n",
    "    duration = None\n",
    "    if metadata:\n",
    "        parts = [part.strip() for part in metadata.split('·')]\n",
    "        if len(parts) >= 1:\n",
    "            level = parts[0]\n",
    "        if len(parts) >= 3:\n",
    "            duration = parts[2]\n",
    "\n",
    "    if course_name:\n",
    "        courses_data.append({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "            'Skills': skills,\n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Level': level,\n",
    "            'Duration': duration\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'coursera_courses.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Course Name', 'Provider', 'Skills', 'Rating', 'Total Reviews', 'Level', 'Duration'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(courses_data)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce31606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to coursera_courses_html.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Path to your local HTML file\n",
    "file_path = '/home/student/Downloads/Courses.html'\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Select all course cards - adjust this selector if needed based on your HTML\n",
    "course_cards = soup.select('li')\n",
    "\n",
    "courses_data = []\n",
    "\n",
    "for card in course_cards:\n",
    "    # Course Name\n",
    "    course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "    course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "    # Provider\n",
    "    provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "    provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "    # Skills you'll gain\n",
    "    skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "    if not skills_tag:\n",
    "        for p in card.select('p'):\n",
    "            strong_tag = p.find('strong')\n",
    "            if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                skills_tag = p\n",
    "                break\n",
    "    skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip() if skills_tag else None\n",
    "\n",
    "    # Rating\n",
    "    rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "    rating = None\n",
    "    if rating_div:\n",
    "        rating_span = rating_div.find('span')\n",
    "        rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "    # Total Reviews\n",
    "    total_reviews = None\n",
    "    review_divs = card.select('div.css-vac8rf')\n",
    "    for div in review_divs:\n",
    "        text = div.text.strip()\n",
    "        if \"reviews\" in text:\n",
    "            total_reviews = text\n",
    "            break\n",
    "\n",
    "    # Metadata (Level and Duration)\n",
    "    metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "    level = None\n",
    "    duration = None\n",
    "    if metadata_p:\n",
    "        parts = [part.strip() for part in metadata_p.text.split('·')]\n",
    "        if len(parts) >= 1:\n",
    "            level = parts[0]\n",
    "        if len(parts) >= 3:\n",
    "            duration = parts[2]\n",
    "\n",
    "    if course_name:  # Only add if course name exists\n",
    "        courses_data.append({\n",
    "            'Course Name': course_name,\n",
    "            'Provider': provider,\n",
    "            'Skills': skills,\n",
    "            'Rating': rating,\n",
    "            'Total Reviews': total_reviews,\n",
    "            'Level': level,\n",
    "            'Duration': duration\n",
    "        })\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'coursera_courses_html.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Course Name', 'Provider', 'Skills', 'Rating', 'Total Reviews', 'Level', 'Duration'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(courses_data)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78576be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "\n",
      "✅ Scraped 100 courses and saved to 'coursera_courses_ajax.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def get_courses_from_page(soup):\n",
    "    course_cards = soup.select('li')\n",
    "    page_courses = []\n",
    "\n",
    "    for card in course_cards:\n",
    "        # Course Name\n",
    "        course_name_tag = card.select_one('a.cds-CommonCard-titleLink h3')\n",
    "        course_name = course_name_tag.text.strip() if course_name_tag else None\n",
    "\n",
    "        # Provider\n",
    "        provider_tag = card.select_one('p.cds-ProductCard-partnerNames')\n",
    "        provider = provider_tag.text.strip() if provider_tag else None\n",
    "\n",
    "        # Skills you'll gain\n",
    "        skills_tag = None\n",
    "        skills_tag = card.find('p', string=lambda t: t and \"Skills you'll gain\" in t)\n",
    "        if not skills_tag:\n",
    "            p_tags = card.select('p')\n",
    "            for p in p_tags:\n",
    "                strong_tag = p.find('strong')\n",
    "                if strong_tag and \"Skills you'll gain\" in strong_tag.text:\n",
    "                    skills_tag = p\n",
    "                    break\n",
    "        skills = None\n",
    "        if skills_tag:\n",
    "            skills = skills_tag.text.replace(\"Skills you'll gain:\", \"\").strip()\n",
    "\n",
    "        # Rating\n",
    "        rating_div = card.find('div', attrs={'aria-label': 'Rating'})\n",
    "        rating = None\n",
    "        if rating_div:\n",
    "            rating_span = rating_div.find('span')\n",
    "            rating = rating_span.text.strip() if rating_span else None\n",
    "\n",
    "        # Total Reviews\n",
    "        total_reviews = None\n",
    "        review_divs = card.select('div.css-vac8rf')\n",
    "        for div in review_divs:\n",
    "            text = div.text.strip()\n",
    "            if \"reviews\" in text:\n",
    "                total_reviews = text\n",
    "                break\n",
    "\n",
    "        # Metadata: level and duration\n",
    "        metadata_p = card.select_one('div.cds-CommonCard-metadata p.css-vac8rf')\n",
    "        metadata = metadata_p.text.strip() if metadata_p else None\n",
    "\n",
    "        level = None\n",
    "        duration = None\n",
    "        if metadata:\n",
    "            parts = [part.strip() for part in metadata.split('·')]\n",
    "            if len(parts) >= 1:\n",
    "                level = parts[0]\n",
    "            if len(parts) >= 3:\n",
    "                duration = parts[2]\n",
    "\n",
    "        if course_name:\n",
    "            page_courses.append({\n",
    "                'Course Name': course_name,\n",
    "                'Provider': provider,\n",
    "                'Skills': skills,\n",
    "                'Rating': rating,\n",
    "                'Total Reviews': total_reviews,\n",
    "                'Level': level,\n",
    "                'Duration': duration\n",
    "            })\n",
    "\n",
    "    return page_courses\n",
    "\n",
    "\n",
    "# === Config ===\n",
    "TARGET_COUNT = 100  # Change this to get more or fewer courses\n",
    "BASE_URL = \"https://www.coursera.org/search?productTypeDescription=Professional%20Certificates&sortBy=BEST_MATCH&page={}\"\n",
    "\n",
    "courses_data = []\n",
    "page = 1\n",
    "\n",
    "while len(courses_data) < TARGET_COUNT:\n",
    "    print(f\"Scraping page {page}...\")\n",
    "\n",
    "    url = BASE_URL.format(page)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    page_courses = get_courses_from_page(soup)\n",
    "\n",
    "    if not page_courses:\n",
    "        print(\"No more courses found.\")\n",
    "        break\n",
    "\n",
    "    courses_data.extend(page_courses)\n",
    "    page += 1\n",
    "    time.sleep(1)  # Be polite to the server\n",
    "\n",
    "# Trim to exact target count\n",
    "courses_data = courses_data[:TARGET_COUNT]\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'coursera_courses_ajax.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['Course Name', 'Provider', 'Skills', 'Rating', 'Total Reviews', 'Level', 'Duration'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(courses_data)\n",
    "\n",
    "print(f\"\\n✅ Scraped {len(courses_data)} courses and saved to '{csv_file}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
